{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import ToTensor, Lambda\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\nbatch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n    \n    \n# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n            \n            \ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n    \n    \n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\n\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")\n\ndata = [[1, 2],[3, 4]]\nx_data = torch.tensor(data)\n\nx_ones = torch.ones_like(x_data) # retains the properties of x_data\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\n\nx_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\nprint(f\"Random Tensor: \\n {x_rand} \\n\")\n\n\nshape = (3,5,)\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"Ones Tensor: \\n {ones_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor}\")\nprint(f\"Shape of tensor: {rand_tensor.shape}\")\n\ntensor = torch.rand(3,4)\n\nprint(f\"Shape of tensor: {tensor.shape}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")\n\nlabels_map = {\n    0: \"T-Shirt\",\n    1: \"Trouser\",\n    2: \"Pullover\",\n    3: \"Dress\",\n    4: \"Coat\",\n    5: \"Sandal\",\n    6: \"Shirt\",\n    7: \"Sneaker\",\n    8: \"Bag\",\n    9: \"Ankle Boot\",\n}\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 3, 3\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n    img, label = training_data[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(labels_map[label])\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-12T09:55:43.474982Z","iopub.execute_input":"2022-06-12T09:55:43.47538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\n\n\n\ntransform = transforms.Compose([transforms.Resize(28),\n                              transforms.CenterCrop(28),\n                              transforms.Grayscale(),\n                              transforms.ToTensor()])\n\ndataset = datasets.ImageFolder(\"../input/transformer1/birds/birds\", transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, shuffle=False, batch_size=16)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=16) \n\n\nimages, labels = next(iter(train_loader))\n\nimshow(images[0], normalize=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T09:56:51.324914Z","iopub.execute_input":"2022-06-14T09:56:51.325305Z","iopub.status.idle":"2022-06-14T09:56:52.299335Z","shell.execute_reply.started":"2022-06-14T09:56:51.325273Z","shell.execute_reply":"2022-06-14T09:56:52.298580Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-06-14T08:32:21.863782Z","iopub.execute_input":"2022-06-14T08:32:21.864133Z","iopub.status.idle":"2022-06-14T08:32:21.873029Z","shell.execute_reply.started":"2022-06-14T08:32:21.864102Z","shell.execute_reply":"2022-06-14T08:32:21.872138Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super(RNNModel, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        \n        self.layer_dim = layer_dim\n        \n        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n        \n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n        import pdb; pdb.set_trace()\n        out, hn = self.rnn(x, h0)\n        out = self.fc(out[:, -1, :])\n        return out\n\nbatch_size = 100\nn_iters = 8000\nnum_epochs = n_iters / (len(train_dataset) / batch_size)\nnum_epochs = int(num_epochs)\n\ntrain_loader = DataLoader(train_dataset, shuffle=False, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size) \n\ninput_dim = 28\nhidden_dim = 3*28*28\nlayer_dim = 1\noutput_dim = 100\n\nmodel = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n\nloss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T09:57:07.315819Z","iopub.execute_input":"2022-06-14T09:57:07.316564Z","iopub.status.idle":"2022-06-14T09:57:07.371357Z","shell.execute_reply.started":"2022-06-14T09:57:07.316527Z","shell.execute_reply":"2022-06-14T09:57:07.370487Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"seq_dim = 28\nloss_list = []\niteration_list = []\naccuracy_list = []\ncount = 0\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view( -1, seq_dim, input_dim))\n        labels = Variable(labels)        \n        optimizer.zero_grad()\n        \n        outputs = model(train)\n        \n#        import pdb; pdb.set_trace()\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        count += 1\n        \n        if count % 250 == 0:\n            \n            correct = 0\n            total = 0\n            \n            for images, labels in test_loader:\n                images = Variable(images.view(-1, seq_dim, input_dim))\n                \n                outputs = model(images)\n                predicted = torch.max(outputs.data, 1)[1]\n                total += labels.size(0)\n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct / float(total)\n            \n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            if count % 500 == 0:\n                # Print Loss\n                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T09:57:13.618150Z","iopub.execute_input":"2022-06-14T09:57:13.618755Z","iopub.status.idle":"2022-06-14T09:57:32.038821Z","shell.execute_reply.started":"2022-06-14T09:57:13.618721Z","shell.execute_reply":"2022-06-14T09:57:32.037398Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"RNN: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"RNN: Accuracy vs Number of iteration\")\nplt.savefig('graph.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T19:17:19.75304Z","iopub.execute_input":"2022-06-12T19:17:19.753399Z","iopub.status.idle":"2022-06-12T19:17:20.119809Z","shell.execute_reply.started":"2022-06-12T19:17:19.753371Z","shell.execute_reply":"2022-06-12T19:17:20.119094Z"},"trusted":true},"execution_count":null,"outputs":[]}]}