{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ninput_size = 11664\nseq_size = 3\nnum_layers = 2\nhidden_size = 2560\nnum_classes = 768\nlearning_rate = 0.05\nbatch_size = 64\nnum_epochs = 2\n\nclass RNNModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNNModel, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size*seq_size, num_classes)\n    \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n        out, _ = self.rnn(x, h0)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:58:24.420866Z","iopub.execute_input":"2022-06-26T10:58:24.421637Z","iopub.status.idle":"2022-06-26T10:58:24.432812Z","shell.execute_reply.started":"2022-06-26T10:58:24.421599Z","shell.execute_reply":"2022-06-26T10:58:24.431774Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize(108),\n                              transforms.CenterCrop(108),\n                              transforms.ToTensor()])\n\ndataset = datasets.ImageFolder(\"../input/birds1/birds/birds\", transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size) \n\nmodel = RNNModel(input_size, hidden_size, num_layers, num_classes).to(device)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nfor epoch in range(num_epochs):\n    for i, (data, targets) in enumerate(train_loader):\n        data = data.to(device=device).flatten(2)\n        targets = targets.to(device=device)\n        \n        scores = model(data)\n        loss = loss_fn(scores, targets)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n        \nprint('Finalizo')\nPATH = './selected_model.pth'\ntorch.save(model, PATH)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T10:58:28.011963Z","iopub.execute_input":"2022-06-26T10:58:28.013918Z","iopub.status.idle":"2022-06-26T11:02:23.248994Z","shell.execute_reply.started":"2022-06-26T10:58:28.013870Z","shell.execute_reply":"2022-06-26T11:02:23.247865Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Finalizo\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = torch.load(\"./selected_model.pth\")\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:06:14.299756Z","iopub.execute_input":"2022-06-26T11:06:14.300359Z","iopub.status.idle":"2022-06-26T11:06:14.472801Z","shell.execute_reply.started":"2022-06-26T11:06:14.300325Z","shell.execute_reply":"2022-06-26T11:06:14.471904Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"RNNModel(\n  (rnn): RNN(11664, 2560, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=7680, out_features=768, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device).flatten(2)\n            y = y.to(device=device)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n        print(f'Got {num_correct} / {num_samples} with accuracy  \\ {(float(num_correct)/float(num_samples))*100:.2f}')\n    model.train()\n    \ncheck_accuracy(test_loader, model)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:06:17.146631Z","iopub.execute_input":"2022-06-26T11:06:17.146988Z","iopub.status.idle":"2022-06-26T11:06:46.502069Z","shell.execute_reply.started":"2022-06-26T11:06:17.146958Z","shell.execute_reply":"2022-06-26T11:06:46.501247Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Got 1762 / 11678 with accuracy  \\ 15.09\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test and write submission_test.csv\nimport csv\nimport os\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\n\nclass NoClassDataset(Dataset):\n    def __init__(self, main_dir, transform):\n        self.main_dir = main_dir\n        self.transform = transform\n        all_imgs = os.listdir(main_dir)\n        self.total_imgs = all_imgs\n\n    def __len__(self):\n        return len(self.total_imgs)\n\n    def __getitem__(self, idx):\n        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n        image = Image.open(img_loc).convert(\"RGB\")\n        tensor_image = self.transform(image)\n        tensor_image = tensor_image.to(device)\n        return tensor_image\n    \n    def getFileName(self, idx):\n        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n        filename = os.path.basename(img_loc)\n        return filename.split(\".\")[0]\n\n#Creamos el csv\n\nwith open('submission.csv', 'w') as file:\n    data = [\"Id\", \"Category\"]\n    writer = csv.writer(file)\n    writer.writerow(data)\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    transform = transforms.Compose([transforms.Resize(108),\n                                     transforms.CenterCrop(108),transforms.ToTensor()])\n    dataset = datasets.ImageFolder('../input/birds1/birds/birds', transform=transform)\n    model = torch.load('./selected_model.pth')\n    model.eval()\n\n    submissions = NoClassDataset('../input/birds1/submission_test/submission_test', transform=transform)\n    submissions_loader = DataLoader(submissions , batch_size=1, shuffle=False)\n\n    dict = dataset.class_to_idx\n    key_list = list(dict.keys())\n    val_list = list(dict.values())\n    \n    for epoch in range(1): #Necesario para iterar las 2000, La longitud del dataset es batch_size x num_epochs\n        for idx, img_normalized in enumerate(submissions_loader):\n            img_normalized = img_normalized.flatten(2)\n            logits = model(img_normalized)\n            probs = torch.nn.functional.softmax(logits, dim=1)\n\n            k = 1\n            top_prob, top_ix = probs[0].topk(k)\n            ix = top_ix.item()\n            prob = top_prob.item()\n            position = val_list.index(top_ix)\n            cls = key_list[position].strip()\n            #import pdb; pdb.set_trace()\n            row = [submissions.getFileName(idx), cls]\n            writer.writerow(row)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T11:13:31.582354Z","iopub.execute_input":"2022-06-26T11:13:31.582736Z","iopub.status.idle":"2022-06-26T11:14:05.925482Z","shell.execute_reply.started":"2022-06-26T11:13:31.582683Z","shell.execute_reply":"2022-06-26T11:14:05.924520Z"},"trusted":true},"execution_count":33,"outputs":[]}]}